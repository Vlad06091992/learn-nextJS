Зачем нужно: чтобы скрыть от индексации конфиденциальные разделы (админка, тестовые страницы),
сэкономить «краулинговый бюджет» и избежать дублирования контента.

# robots.txt
User-agent: *        # Правило для всех ботов
Disallow: /admin/    # Не сканировать раздел /admin/
Allow: /             # Можно сканировать остальные страницы
Sitemap: https://example.com/sitemap.xml  # Ссылка на карту сайта
